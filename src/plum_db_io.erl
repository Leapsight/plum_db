%% =============================================================================
%%  plum_db_exporter.erl -
%%
%%  Copyright (c) 2016-2023 Leapsight. All rights reserved.
%%
%%  Licensed under the Apache License, Version 2.0 (the "License");
%%  you may not use this file except in compliance with the License.
%%  You may obtain a copy of the License at
%%
%%     http://www.apache.org/licenses/LICENSE-2.0
%%
%%  Unless required by applicable law or agreed to in writing, software
%%  distributed under the License is distributed on an "AS IS" BASIS,
%%  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
%%  See the License for the specific language governing permissions and
%%  limitations under the License.
%% =============================================================================

%% -----------------------------------------------------------------------------
%% @doc
%% @end
%% -----------------------------------------------------------------------------
-module(plum_db_io).
-behaviour(gen_server).
-include_lib("kernel/include/logger.hrl").

-define(EXPORT_SPEC, #{
    <<"path">> => #{
        alias => path,
        key => path,
        required => true,
        allow_null => false,
        allow_undefined => false,
        validator => fun
            (X) when is_list(X) ->
                {ok, X};
            (X) when is_binary(X) ->
                {ok, unicode:characters_to_list(X)};
            (_) ->
                false
        end
    }
}).

-define(IMPORT_SPEC, #{
    <<"filename">> => #{
        alias => filename,
        key => filename,
        required => true,
        allow_null => false,
        allow_undefined => false,
        validator => fun
            (X) when is_list(X) ->
                {ok, X};
            (X) when is_binary(X) ->
                {ok, unicode:characters_to_list(X)};
            (_) ->
                false
        end
    }
}).

-define(STATUS_SPEC, #{
    <<"filename">> => #{
        alias => filename,
        key => filename,
        required => false,
        allow_null => false,
        allow_undefined => false,
        validator => fun
            (X) when is_list(X) ->
                {ok, X};
            (X) when is_binary(X) ->
                {ok, unicode:characters_to_list(X)};
            (_) ->
                false
        end
    }
}).


-record(state, {
    status          ::  status(),
    timestamp       ::  non_neg_integer() | undefined,
    helper          ::  pid() | undefined,
    filename        ::  file:filename() | undefined
}).


-type status()      ::  export_in_progress | import_in_progress | undefined.
-type info()        ::  #{
    filename => file:filename(),
    timestamp => non_neg_integer()
}.


%% API
-export([export/1]).
-export([import/1]).
-export([start_link/0]).
-export([status/0]).
-export([status/1]).

%% GEN_SERVER CALLBACKS
-export([init/1]).
-export([handle_info/2]).
-export([terminate/2]).
-export([code_change/3]).
-export([handle_call/3]).
-export([handle_cast/2]).



%% =============================================================================
%% API
%% =============================================================================


%% -----------------------------------------------------------------------------
%% @doc
%% @end
%% -----------------------------------------------------------------------------
start_link() ->
    gen_server:start_link({local, ?MODULE}, ?MODULE, [], []).


%% -----------------------------------------------------------------------------
%% @doc Exports all data in the directory indicated by Path.
%% @end
%% -----------------------------------------------------------------------------
-spec export(file:filename_all() | map()) ->
    {ok, info()} | {error, term()}.

export(Map0) when is_map(Map0) ->
    try maps_utils:validate(Map0, ?EXPORT_SPEC) of
        Map1 ->
            gen_server:call(?MODULE, {export, Map1})
    catch
        error:Reason ->
            {error, Reason}
    end;

export(Path) ->
    export(#{path => Path}).


%% -----------------------------------------------------------------------------
%% @doc
%% @end
%% -----------------------------------------------------------------------------
status() ->
    status(#{}).


%% -----------------------------------------------------------------------------
%% @doc
%% @end
%% -----------------------------------------------------------------------------
-spec status(file:filename_all() | map()) ->
    undefined | {status(), non_neg_integer()} | {error, unknown}.

status(Map0) when is_map(Map0) ->
    try maps_utils:validate(Map0, ?STATUS_SPEC) of
        Map1 ->
            gen_server:call(?MODULE, {status, Map1})
    catch
        error:Reason ->
            {error, Reason}
    end;

status(Filename) ->
    status(#{filename => Filename}).


%% -----------------------------------------------------------------------------
%% @doc Imports data from a file previously generated by calling
%% {@link export/1}.
%% @end
%% -----------------------------------------------------------------------------
-spec import(file:filename_all() | map()) -> {ok, info()} | {error, term()}.

import(Map0) when is_map(Map0) ->
    try maps_utils:validate(Map0, ?IMPORT_SPEC) of
        Map1 ->
            gen_server:call(?MODULE, {import, Map1})
    catch
        error:Reason ->
            {error, Reason}
    end;

import(Filename) ->
    import(#{filename => Filename}).





%% =============================================================================
%% GEN_SERVER CALLBACKS
%% =============================================================================

init([]) ->
    {ok, #state{}}.


handle_call({export, Map}, _From, #state{status = undefined} = State0) ->
    {ok, State1} = async_export(Map, State0),
    Export = #{
        filename => unicode:characters_to_binary(State1#state.filename),
        timestamp => State1#state.timestamp
    },
    {reply, {ok, Export}, State1};

handle_call({export, _}, _From, State) ->
    {reply, {error, State#state.status}, State};

handle_call({import, Map}, _From, #state{status = undefined} = State0) ->
    {ok, State1} = async_import(Map, State0),
    Restore = #{
        filename => unicode:characters_to_binary(State1#state.filename),
        timestamp => State1#state.timestamp
    },
    {reply, {ok, Restore}, State1};

handle_call({import, _}, _From, State) ->
    {reply, {error, State#state.status}, State};

handle_call({status, Map}, _From, State) when map_size(Map) =:= 0 ->
    {reply, {ok, State#state.status}, State};

handle_call(
    {status, #{filename := Filename}},
    _From,
    #state{filename = Filename} = State) ->
    Reply = case State#state.status of
        undefined ->
            read_head(Filename);
        Status ->
            Secs = elapsed_secs(State#state.timestamp),
            {ok, #{status => Status, elapsed_time_secs => Secs}}
    end,
    {reply, Reply, State};

handle_call({status, #{filename := Filename}}, _From, State) ->
    {reply, read_head(Filename), State};

handle_call(_, _, State) ->
    {reply, ok, State}.


handle_cast(_Event, State) ->
    {noreply, State}.

handle_info({export_reply, ok, Pid}, #state{helper = Pid} = State) ->
    Secs = elapsed_secs(State#state.timestamp),
    ok = notify_export_finished([State#state.filename, Secs]),
    {noreply, State#state{status = undefined, helper = undefined}};

handle_info({export_reply, {error, Reason}, Pid}, #state{helper = Pid} = State) ->
    Secs = elapsed_secs(State#state.timestamp),
    ok = notify_export_error([Reason, State#state.filename, Secs]),
    {noreply, State#state{status = undefined, helper = undefined}};

handle_info({import_reply, {ok, Counters}, Pid}, #state{helper = Pid} = State) ->
    #{read_count := N, merged_count := M} = Counters,
    Secs = elapsed_secs(State#state.timestamp),
    ok = notify_import_finished([State#state.filename, Secs, N, M]),
    {noreply, State#state{status = undefined, helper = undefined}};

handle_info({import_reply, {error, Reason}, Pid}, #state{helper = Pid} = State) ->
    Secs = elapsed_secs(State#state.timestamp),
    ok = notify_import_error([State#state.filename, Reason, Secs]),
    {noreply, State#state{status = undefined, helper = undefined}};

handle_info(Info, State) ->
    ?LOG_DEBUG(#{
        description => "Unexpected event received",
        event => Info
    }),
    {noreply, State}.


terminate(_Reason, _State) ->
    ok.


code_change(_OldVsn, State, _Extra) ->
    {ok, State}.



%% =============================================================================
%% PRIVATE
%% =============================================================================



%% @private
async_export(#{path := Path} , State0) ->
    Ts = erlang:system_time(),
    Filename = "export." ++ integer_to_list(Ts) ++ ".pdb",
    File = filename:join([Path, Filename]),
    Me = self(),
    Pid = spawn_link(fun() ->
        case do_export(File, Ts) of
            ok ->
                Me ! {export_reply, ok, self()};
            {error, _} = Error ->
                Me ! {export_reply, Error, self()}
        end
    end),
    State1 = State0#state{
        filename = File,
        helper = Pid,
        timestamp = Ts,
        status = export_in_progress
    },
    {ok, State1}.


%% @private
do_export(File, Ts) ->
    Opts = [
        {name, log},
        {file, File},
        {type, halt},
        {size, infinity},
        {head, #{
            format => dvvset_log,
            mod => ?MODULE,
            mod_vsn => mod_vsn(),
            node => partisan:node(),
            prefixes => plum_db_config:get(prefixes),
            partitions => plum_db_config:get(partitions),
            timestamp => Ts
        }}
    ],

    case disk_log:open(Opts) of
        {ok, Log} ->
            _ = notify_export_started(File),
            build_export(Log);
        {error, _} = Error ->
            Error
    end.


%% @private
mod_vsn() ->
    {vsn, Vsn} = lists:keyfind(vsn, 1, ?MODULE:module_info(attributes)),
    Vsn.


%% @private
build_export(Log) ->
    Iterator = plum_db:iterator({'_', '_'}),
    try
        Acc1 = build_export(Iterator, Log, []),
        %% We log the remaining elements
        log(Acc1, Log)
    catch
        throw:Reason ->
            {error, Reason}
    after
        ok = plum_db:iterator_close(Iterator),
        disk_log:close(Log)
    end.


%% @private
build_export(Iterator, Log, Acc0) ->
    case plum_db:iterator_done(Iterator) of
        true ->
            Acc0;
        false ->
            %% iterator_element/1 gets the whole prefixed object without
            %% resolving conflicts
            E = plum_db:iterator_element(Iterator),
            Acc1 = maybe_append(E, Acc0),
            Acc2 = maybe_log(Acc1, Log),
            build_export(plum_db:iterate(Iterator), Log, Acc2)
    end.


%% @private
maybe_append(E, Acc) ->
    %% TODO add a callback function the user can add to filter out objects
    [E | Acc].


%% @private
maybe_log(Acc, Log) when length(Acc) =:= 500 ->
    ok = log(Acc, Log),
    [];

maybe_log(Acc, _) ->
    Acc.


%% @private
log([], _) ->
    ok;

log(L, Log) ->
    ok = maybe_throw(disk_log:log_terms(Log, L)),
    maybe_throw(disk_log:sync(Log)).


%% @private
maybe_throw(ok) -> ok;
maybe_throw({error, Reason}) -> throw(Reason).


%% @private
async_import(#{filename := Filename}, State0) ->
    %% @TODO We might want to stop AAE so that
    %% (1) we avoid writing the hahstree during import and
    %% (2) avoid exchanges too.
    Ts = erlang:system_time(),
    Me = self(),
    Pid = spawn_link(fun() ->
        case do_import(Filename) of
            {ok, _Counters} = OK ->
                Me ! {import_reply, OK, self()};
            {error, _} = Error ->
                Me ! {import_reply, Error, self()}
        end
    end),
    State1 = State0#state{
        filename = Filename,
        helper = Pid,
        timestamp = Ts,
        status = import_in_progress
    },
    {ok, State1}.


%% @private
do_import(Filename) ->
    Opts =  [
        {name, log},
        {mode, read_only},
        {file, Filename}
    ],

    case disk_log:open(Opts) of
        {ok, Log} ->
            ok = notify_import_started([Filename, 0, 0]),
            do_import_aux(Log);
        {repaired, Log, {recovered, Rec}, {badbytes, Bad}} ->
            ok = notify_import_started([Filename, Rec, Bad]),
            do_import_aux(Log);
        {error, _} = Error ->
            Error
    end.


do_import_aux(Log) ->
    try
        Counters0 = #{read_count => 0, merged_count => 0},
        import_chunk({head, disk_log:chunk(Log, start)}, Log, Counters0)
    catch
       _:Reason ->
            {error, Reason}
    after
        _ = disk_log:close(Log)
    end.



%% @private
import_chunk(eof, Log, Counters) ->
    ok = disk_log:close(Log),
    {ok, Counters};

import_chunk({error, _} = Error, Log, _) ->
    _ = disk_log:close(Log),
    Error;

import_chunk({head, {Cont, [H|T]}}, Log, Counters) ->
    ok = validate_head(H),
    import_chunk({Cont, T}, Log, Counters);

import_chunk({Cont, Terms}, Log, Counters0) ->
    try
        {ok, Counters} = import_terms(Terms, Counters0),
        import_chunk(disk_log:chunk(Log, Cont), Log, Counters)
    catch
       _:Reason ->
            {error, Reason}
    end.



%% @private
import_terms([H|T], #{read_count := N, merged_count := M} = Counters) ->
    case maybe_migrate(H) of
        {PKey, Object} ->
            case plum_db:merge({PKey, undefined}, Object) of
                true ->
                    import_terms(
                        T, Counters#{read_count => N + 1, merged_count => M + 1});
                false ->
                    import_terms(T, Counters#{read_count => N + 1})
            end;
        skip ->
            import_terms(T, Counters#{read_count => N + 1})
    end;

import_terms([], Counters) ->
    {ok, Counters}.


%% @private

maybe_migrate({{Prefix, Key}, Object}) ->
    %% TODO use user callback if present as second Arg
    case maybe_rename_prefix(Prefix) of
        skip ->
            skip;
        Renamed ->
            {{Renamed, Key}, migrate_object(Object)}
    end.


%% @private
maybe_rename_prefix(Prefix) ->
    %% TODO use user callback if present as second Arg
    Prefix.


%% @private
migrate_object({metadata, _} = Object) ->
    %% For versions < 1.1.0
    setelement(1, Object, object);

migrate_object({object, _} = Object) ->
    Object.


%% @private
validate_head(#{format := dvvset_log}) ->
    ok;

validate_head(H) ->
    throw({invalid_header, H}).


%% @private
read_head(Filename) ->
    Opts =  [
        {name, log},
        {mode, read_only},
        {file, Filename}
    ],
    Acc = #{filename => unicode:characters_to_binary(Filename)},
    case disk_log:open(Opts) of
        {ok, Log} ->
            do_read_head(Log, Acc);
        {repaired, Log, {recovered, Rec}, {badbytes, Bad}} ->
            do_read_head(Log, Acc#{recovered => Rec, bad_bytes => Bad});
        {error, no_such_log} ->
            {error, not_found};
        {error, _} = Error ->
            Error
    end.


%% @private
do_read_head(Log, Acc0) ->
    try
        case disk_log:chunk(Log, start) of
            {_Cont, [H|_]} ->
                ok = validate_head(H),
                Acc1 = Acc0#{
                    status => ok,
                    bad_bytes => 0
                },
                {ok, maps:merge(Acc1, H)};
            {_Cont, [H|_], BadBytes} ->
                ok = validate_head(H),
                Acc1 = Acc0#{
                    status => ok,
                    bad_bytes => BadBytes
                },
                {ok, maps:merge(Acc1, H)};
            eof ->
                {ok, Acc0#{status => invalid_format}};
            {error, {corrupt_log_file, _}} ->
            {ok, Acc0#{status => corrupt, bad_bytes => 0}};
            {error, {blocked_log, _}} ->
                {ok, Acc0#{status => blocked, bad_bytes => 0}};
            {error, _} = Error ->
                Error
        end
    catch
       _:Reason ->
            {error, Reason}
    after
        _ = disk_log:close(Log)
    end.


%% @private
notify_export_started(File) ->
    ?LOG_NOTICE(#{
        description => "Export started",
        filename => File
    }),
    plum_db_events:notify(export_started, File).


%% @private
notify_export_finished([Filename, Time] = Args) ->
    ?LOG_NOTICE(#{
        description => "Finished exporting",
        filename => Filename,
        elapsed_time_secs => Time
    }),
    plum_db_events:notify(export_finished, Args).


%% @private
notify_export_error([Reason, Filename, Time] = Args)  ->
    ?LOG_ERROR(#{
        description => "Error exporting",
        filename => Filename,
        reason => Reason,
        elapsed_time_secs => Time
    }),
    plum_db_events:notify(export_failed, Args).


%% @private
notify_import_started([Filename, Rec, Bad]) ->
    ?LOG_NOTICE(#{
        description => "Started importing",
        filename => Filename,
        recovered => Rec,
        bad_bytes => Bad
    }),
    plum_db_events:notify(import_started, Filename).


%% @private
notify_import_finished([Filename, Time, Read, Merged] = Args) ->
    ?LOG_NOTICE(#{
        description => "Finished importing",
        filename => Filename,
        elapsed_time_secs => Time,
        read_count => Read,
        merged_count => Merged
    }),
    plum_db_events:notify(import_finished, Args).


%% @private
notify_import_error([Filename, Reason, Time] = Args) ->
    ?LOG_ERROR(#{
        description => "Import failed",
        filename => Filename,
        reason => Reason,
        elapsed_time_secs => Time
    }),
    plum_db_events:notify(import_failed, Args).


%% @private
elapsed_secs(Timestamp) ->
    Elapsed = erlang:system_time() - Timestamp,
    erlang:convert_time_unit(Elapsed, native, second).

